{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432d330b-9796-46e0-a1b3-f05592d63e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b46fd9-658c-4829-8448-63a4a05adc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceEndpoint(repo_id=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",task='text-generation')\n",
    "enhancer_model=ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74e0c7a-5622-44e9-b793-7ad8f98cd0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panka\\langchain\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\panka\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29cd3150-1c8a-4c2b-b627-d37180687e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"\"\"You are a precise writing enhancement assistant. Your ONLY job is to improve the expression of text — not its ideas.\n",
    "You MUST:\n",
    "- Fix grammatical errors and spelling mistakes\n",
    "- Improve sentence structure and clarity\n",
    "- Improve logical flow between sentences\n",
    "- Keep the improved text approximately the same length as the input\n",
    "\n",
    "You MUST NOT:\n",
    "- Add any new ideas, arguments, or information not present in the original\n",
    "- Remove any core meaning or factual claim from the original\n",
    "- Change the factual intent of any sentence\n",
    "- Expand content beyond style and grammatical improvement\n",
    "- Add preambles like \"Here is the improved text\" — return ONLY the enhanced text\n",
    "- Ask any further questions to user just enhance the text and return it\"\"\"),\n",
    "        (\"human\",\"\"\"Below are examples of how to enhance text:\n",
    "Input: I am doing project on AI which is very good and it help many people in future.\n",
    "Output: I am working on an AI project that has strong potential to help many people in the future.\n",
    "\n",
    "Now enchance the following text\n",
    "\n",
    "Input: {prompt}\n",
    "Output:\"\"\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c08a95a-b178-4b5b-bb38-a303e706b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=embedding_model.embed_query(\"I am good boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53527394-f4ee-4971-b3e0-64fd4c366011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2213b0f-a444-4674-950d-3e50b18b8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(arr1,arr2):\n",
    "    arr1=np.array(arr1)\n",
    "    arr2=np.array(arr2)\n",
    "    num=(arr1*arr2).sum()\n",
    "    den=np.sqrt((arr1**2).sum())*np.sqrt((arr2**2).sum())\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83d2e6b4-e16f-4af0-9d94-dd677d406da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_chain=RunnableParallel(\n",
    "    {\n",
    "        \"orignal_text\":RunnablePassthrough(),\n",
    "        \"enhanced_text\": chat_template|enhancer_model|parser\n",
    "    }\n",
    ")\n",
    "parl_chain= RunnableParallel({\n",
    "    \"enhanced_text\":RunnableLambda(lambda x:x['enhanced_text']),\n",
    "    \"orignal_embedding\":RunnableLambda(lambda x:embedding_model.embed_query(x['orignal_text']['prompt'])),\n",
    "    \"enhanced_embedding\":RunnableLambda(lambda x:embedding_model.embed_query(x['enhanced_text']))\n",
    "})\n",
    "parl_chain_2= RunnableParallel({\n",
    "    \"enhanced_text\":RunnableLambda(lambda x:x['enhanced_text']),\n",
    "    \"similarity\": RunnableLambda(lambda x:cosine_similarity(x['orignal_embedding'],x['enhanced_embedding']))\n",
    "})\n",
    "\n",
    "final_runnable=enhanced_chain | parl_chain | parl_chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61cbc8a2-8970-462a-81e8-4841b84ca89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=final_runnable.invoke({\"prompt\":\"I am an ai engineer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9767e022-49a1-4b00-9c55-f27d9a8a113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enhanced_text': 'I am an artificial intelligence engineer.',\n",
       " 'similarity': np.float64(0.8844137603967079)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf2aba91-6d89-40a5-a2ba-d773879b276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enhanced_text': 'The medicine should not be administered to children under 5, and pregnant women must avoid it entirely.',\n",
       " 'similarity': np.float64(0.9781912909849053)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=final_runnable.invoke({\"prompt\":\"The medicine should not be given to children under 5 and pregnant women must avoid it completely.\"})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8002dec8-c040-48b8-9249-c48c4fbf9bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enhanced_text': 'He is a good boy.',\n",
       " 'similarity': np.float64(0.975991228455573)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=final_runnable.invoke({\"prompt\":\"He are a good boy.\"})\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
